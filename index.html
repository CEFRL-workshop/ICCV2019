<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Joint Workshop on Efficient Deep Learning in Computer Vision</title>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css" />
    <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css' />
    <link href="EDLCVatCVPR2020/css/style.css" rel="stylesheet" type="text/css" />
</head>

<body>

    <div class="container">
        <table border="0" align="center">
            <tr>
                <td width="700" align="center" valign="middle">
                    <span class="title">Joint Workshop on Efficient Deep Learning in Computer Vision<br />CVPR Workshop, 2020</span>
                </td>
            </tr>
            <tr>
                <td>
                    <p><img src="EDLCVatCVPR2020/figures/CVPR2020.jpg" width="1000" align="middle" /></p>
                </td>
            </tr>
        </table>
    </div>

    </br>

    <div class="container">
        <div class="overview">
            <h1>1.TECHNICAL INFORMATION</h1>
            <h2>Workshop title</h2>
            <p><strong>Workshop on Efficient Deep Learning for Computer Vision</strong></p>
            <h2>Duration</h2>
            <p><strong>Full day: June 15, 2020</strong></p>
            <h2>Topics</h2>
            <p>Computer Vision has a long history of academic research, and recent advances in deep learning have provided significant improvements in the ability to understand visual content. As a result of these research advances on problems such as object classification, object detection, and image segmentation, there has been a rapid increase in the adoption of Computer Vision in industry; however, mainstream Computer Vision research has given little consideration to speed or computation time, and even less to constraints such as power/energy, memory footprint and model size. The workshop has three main goals on solving and discussing efficiency in Computer Vision:</p>
            <p>First, the workshop aims to create a venue for a consideration of the new generation of problems that arise as Computer Vision meets mobile and AR/VR systems constraints, to bring together researchers, educators and practitioners who are interested in techniques as well as applications of compact, efficient neural network representations. The workshop discussions will establish close connection between researchers in machine learning and computer vision communities and engineers in industry, and to benefit both academic researchers as well as industrial practitioners. </p>
            <p>Second, the workshop aims at reproducibility and comparability of methods for compact and efficient neural network representations, and on-device machine learning. Thus a set of benchmarking tasks (image classification, visual question answering) will be provided together with defined data sets, in order to compare the performance of neural network compression methods on the same networks. Submissions are encouraged (but not required) to use these tasks and data sets in their work. Also, contributors are encouraged to make their code available.</p>
            <p>Third, the workshop aims to discuss the next steps in developing efficient feature representations from three aspects: energy efficient, label efficient, and sample efficient. Despite DNNs are brain-inspired and can achieve or even surpass human-level performance on a variety of challenging computer vision tasks, they continue to trail humans’ abilities in many aspects, such as high energy-efficiency and the ability to perform low-shot learning (learning novel concepts from very few examples). Therefore, the next generation of feature representation and learning techniques should aim to tackle recognition tasks with significantly reduced computational complexity, using as little training data as people need, and to generalize to a range of different tasks beyond the one task the model was trained on. </p>
            <h3>Particular topics that will be covered</h3>
            <ul>
                <li><strong>Mobile and AR/VR Applications</strong></li>
                <ul>
                    <li>Novel mobile and AR/VR applications using Computer Vision such as image processing (e.g. style transfer, body tracking, face tracking) and augmented reality</li>
                    <li>oLearning efficient deep neural networks under memory and computation constraints for on-device applications</li>
                </ul>
                <li><strong>Efficient Neural Network and Architecture Search</strong></li>
                <ul>
                    <li>Compact and efficient neural network architecture for mobile and AR/VR devices</li>
                    <li>Hardware (latency, energy) aware neural network architectures search, targeted for mobile and AR/VR devices</li>
                    <li>Efficient architecture search algorithm for different vision tasks (detection, segmentation etc.)</li>
                    <li>Optimization for Latency, Accuracy and Memory usage, as motivated by embedded devices</li>
                </ul>
                <li><strong>Neural Network Compression</strong></li>
                <ul>
                    <li>Model compression (sparsification, binarization, quantization, pruning, thresholding and coding etc.) for efficient inference with deep networks and other ML models</li>
                    <li>Scalable compression techniques that can cope with large amounts of data and/or large neural networks (e.g., not requiring access to complete datasets for hyperparameter tuning and/or retraining)</li>
                    <li>Hashing (Binary) Codes Learning</li>
                </ul>
                <li><strong>Low-bit Quantization Network and Hardware Accelerators</strong></li>
                <ul>
                    <li>Investigations into the processor architectures (CPU vs GPU vs DSP) that best support mobile applications</li>
                    <li>Hardware accelerators to support Computer Vision on mobile and AR/VR platforms</li>
                    <li>Low-precision training/inference & acceleration of deep neural networks on mobile devices</li>
                </ul>
                <li><strong>Dataset and benchmark</strong></li>
                <ul>
                    <li>Open datasets and test environments for benchmarking inference with efficient DNN representations</li>
                    <li>Metrics for evaluating the performance of efficient DNN representations</li>
                    <li>Methods for comparing efficient DNN inference across platforms and tasks</li>
                </ul>
                <li><strong>Label/sample/feature efficient learning</strong></li>
                <ul>
                    <li>Label Efficient Feature Representation Learning Methods, e.g. Unsupervised Learning, Domain Adaptation, Weakly Supervised Learning and SelfSupervised Learning Approaches</li>
                    <li>Sample Efficient Feature Learning Methods, e.g. Meta Learning</li>
                    <li>Low Shot learning Techniques</li>
                    <li>New Applications, e.g. Medical Domain</li>
                </ul>
            </ul>
        </div>
    </div>

    <br />

    <div class="container" text-align="left">
        <div class="overview">
            <h1>2.ORGANIZERS AND SPEAKERS</h1>
            <h2>Organizers</h2>
                <ul>
                    <li><strong>Li Liu,</strong> Assistant Professor, University of Oulu, Finland</li>
                    <p>li.liu@oulu.fi</p>
                    <li><strong>Yu Liu,</strong> Postdoc researcher at KU Leuven</li>
                    <p>yu.liu@esat.kuleuven.be</p>
                    <li><strong>Wanli Ouyang,</strong> Senior lecturer, University of Sydney</li>
                    <p>wanli.ouyang@sydney.edu.au</p>
                    <li><strong>Jiwen Lu,</strong> Associate Professor, Tsinghua University, China</li>
                    <p>lujiwen@tsinghua.edu.cn</p>
                    <li><strong>Matti Pietikäinen,</strong> Professor University of Oulu</li>
                    <p>mkp@ee.oulu.fi</p>
                    <li><strong>Luc Van Gool,</strong> Professor, ETH Zurich</li>
                    <p>vangool@vision.ee.ethz.ch</p>
                    <li><strong>Peter Vajda,</strong> Research Scientist Manager at Facebook</li>
                    <p>vajdap@fb.com</p>
                    <li><strong>Peizhao Zhang,</strong> Research Scientist at Facebook</li>
                    <p>stzpz@fb.com</p>
                    <li><strong>Pete Warden,</strong> Staff Research Engineer at Google</li>
                    <p>petewarden@google.com</p>
                    <li><strong>Kurt Keutzer,</strong> Professor at UC Berkeley</li>
                    <p>kurt.keutzer@gmail.com</p>
                    <li><strong>Jonathan Dekhtiar,</strong> Deep Learning Engineer, Nvidia, Israel</li>
                    <p>jdekhtiar@nvidia.com</p>
                    <li><strong>Wojciech Samek,</strong> Fraunhofer Heinrich Hertz Institute, Germany</li>
                    <p>wojciech.samek@hhi.fraunhofer.de</p>
                    <li><strong>Yingyan Lin,</strong> Rice University, US</li>
                    <p>yingyan.lin@rice.edu</p>
                    <li><strong>Werner Bailer,</strong> Joanneum Research, Austria</li>
                    <p>werner.bailer@joanneum.at</p>
                </ul>
            <h2>Invited Speakers</h2>
            <ul>
                <li><strong>Prof. Song Han,</strong> Assistant Professor at MIT</li>
                <li><strong>Prof. Philip Torr,</strong> University of Oxford, the United Kingdom</li>
                <li><strong>Prof. Bill Dally,</strong> Stanford University</li>
                <li><strong>Prof. Nic Lane,</strong> Oxford and Program Director Samsung AI Center, Cambridge</li>
                <li><strong>Prof. Diana Marculescu,</strong> CMU</li>
                <li><strong>Prof. Chelsea Finn,</strong> Stanford University</li>
            </ul>
        </div>
    </div>

    </br>

    <div class="container">
        <div class="overview">
            <h1>3.LOGISTICS</h1>            
            <ul>
                <li>Preference for half-day or full-day event:<strong> Full-day event</strong></li>
                <li>Estimated numbers of orals, posters, and invited talks, with rough program outline</li>
                <ul>
                    <li>6 invited talks, 9 oral presentation, 9 posters, 6 panelists</li>
                    </br>
                    <p>8:50-9:00 Welcome by organizers</p>
                    <p>9:00-9:30 Invited talk: <strong>Prof. Philip Torr (Oxford University)</strong></p>
                    <p>9:30-10:00 Invited talk:  <strong>Prof. Nic Lane (Oxford University)</strong></p>
                    </br>
                    <p>10:00-10:30 Café break</p>
                    </br>
                    <p>10:30-10:40 Submitted paper presentation</p>
                    <p>10:40-10:50 Submitted paper presentation</p>
                    <p>10:50-11:00 Submitted paper presentation</p>
                    </br>
                    <p>11:00-11:30 Keynote talk: <strong>Prof. Song Han (MIT)</strong></p>
                    <p>11:30-12:00 Invited talk: <strong>Prof. Diana Marculescu (CMU)</strong></p>
                    <p>12:00-12:10 Submitted paper presentation</p>
                    <p>12:10-12:20 Submitted paper presentation</p>
                    <p>12:20-12:30 Submitted paper presentation</p>
                    </br>
                    <p>12:30-13:30 Lunch break</p>
                    </br>
                    <p>13:30-14:00 Keynote talk: <strong>Prof. Bill Dally (Stanford)</strong></p>
                    <p>14:00-14:30 Invited talk: <strong>Prof. Chelsea Finn (Stanford)</strong></p>
                    <p>14:30-14:40 Submitted paper presentation</p>
                    <p>14:40-14:50 Submitted paper presentation</p>
                    <p>14:50-15:00 Submitted paper presentation</p>
                    </br>
                    <p>15:00-16:00 <strong>Poster session</strong> by paper submission</p>
                    </br>
                    <p>16:00-17:30 <strong>Panel presentations</strong> and discussion on Efficient deep learning algorithms. <strong>Moderator: Luc Van Gool</strong></p>
                    <p>17:30-17:45 Closing awards for <strong>best paper and best poster</strong></p>
                    </br>
                </ul>
                <li>Expected number of paper submissions: Expected more than 50 papers submitted</li>
                <li>Tentative program committee</li>
                <ul>
                    <li>Amir Hossein Ashouri, University of Toronto </li>
                    <li>Martin Winter, JOANNEUM RESEARCH</li>
                    <li>Zornitsa Kozareva, Google</li>
                    <li>Raphael Tang, University of Waterloo</li>
                    <li>Xiaofan Xu, Intel</li>
                    <li>Ting Chen, University of California, Los Angeles</li>
                    <li>Zenglin Xu, University of Science and Technology of China</li>
                    <li>Diana Marculescu, Carnegie Mellon University</li>
                    <li>Lixin Fan, JD</li>
                    <li>Tinghuai Wang, Nokia</li>
                    <li>Naiyan Wang, The Hong Kong University of Science and Technology Zhendong Zhang, Xidian University</li>
                    <li>Hsin-Pai Cheng, Duke University</li>
                    <li>Keiji Yanai, The University of Electro-Communications</li>
                    <li>Peter M. Roth, Graz University of Technology</li>
                    <li>Haoji Hu, Zhejiang University</li>
                    <li>Yurong Chen, Intel</li>
                    <li>Francesco Cricri, Nokia Technologies</li>
                    <li>Yoojin Choi, Samsung Electronics</li>
                    <li>Brian Kulis, Boston University</li>
                    <li>Elliot Crowley, The University of Edinburgh</li>
                    <li>Navneet Dalal, Flutter, USA</li>
                    <li>Svetlana Lazebnik, Illinois, USA</li>
                    <li>Guoying Zhao, University of Oulu, Finland</li>
                    <li>Krystian Mikolajczyk, Imperial College London, UK</li>
                    <li>Xiaogang Wang, Chinese University of HongKong, China</li>
                    <li>Xiaoyang Tan, Nanjing, China</li>
                    <li>Bill Triggs, INRIA, France</li>
                    <li>Lei Zhang, Hong Kong Polytechnic University, China</li>
                    <li>Zhen Lei, Chinese Academy of Sciences, China</li>
                    <li>Bolei Zhou, MIT, USA</li>
                    <li>Liang Wang, Chinese Academy of Sciences, China </li>
                    <li>Jianxin Wu, Nanjing University, China</li>
                    <li>Jakob Verbeek, INRIA, France </li>
                    <li>Tinne Tyutelaars, KU Leuven</li>
                    <li>Weisheng Dong, Xidian University, China</li>
                    <li>Xilin Chen, Chinese Academy of Sciences, China</li>
                    <li>Ross Girshick, Facebook AI Research, USA</li>
                    <li>Jingdong Wang, Microsoft Research Asia, China</li>
                    <li>Paul Fieguth, University of Waterloo, Canada</li>
                    <li>Dacheng Tao, University of Technology Sydney, Australia</li>
                    <li>Liang Zheng, Singapore University of Technology and Design, Singapore</li>
                    <li>Chunhua Shen, University of Adelaide, Australia</li>
                    <li>Xiaopeng Hong, Xi'an Jiaotong University, China</li>
                    <li>Miguel Bordallo, VTT Technical Research Centre, Finland</li>
                    <li>Jian Li, National University of Defense Technology, China</li>
                    <li>Jiashi Feng, National University of Singapore, Singapore</li>
                    <li>Qixiang Ye, University of the Chinese Academy of Sciences, China</li>
                </ul>
                <li>Expected audience from academia working on model compression, deep learning</li>
                <li>No special space or equipment requests.</li>
                <li>We are planning to run best poster award and best paper competition.</li>
            </ul>
        </div>
    </div>

    <div class="container">
        <div class="overview">
            <h1>4.IMPORTANT DATES</h1>
            <ul>
                <li>Workshop paper submission deadline: March 8, 2020 pst</li>
                <li>Notification to authors: April 1, 2020 pst</li>
                <li>Camera ready deadline: April 10, 2020 pst</li>
            </ul>
        </div>
    </div>

    </br>

    <div class="containersmall">
        <p>Please contact <a href="li.liu@oulu.fi">Li Liu</a> if you have question. The webpage template is by the courtesy of awesome <a href="https://gkioxari.github.io/">Georgia</a>.</p>
    </div>

    <!--<p align="center" class="acknowledgement">Last updated: Jan. 6, 2017</p>-->
</body>
</html>
